{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dow Jones Industrial Average.\n",
    "We get the dataset from Kaggle:\n",
    "https://www.kaggle.com/datasets/mnassrib/dow-jones-industrial-average\n",
    "\n",
    "* The purpose of this notebook is to perform feature engineering tasks in\n",
    "order to augment the data in this table so we can create a more powerful and\n",
    "efficient linear regression model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Reading the dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "                Close       Open       High        Low   Volume Change %\nDate                                                                    \n2019-12-31  28,538.44  28,414.64  28,547.35  28,376.49  193.34M    0.27%\n2019-12-30  28,462.14  28,654.76  28,664.69  28,428.98  185.07M   -0.64%\n2019-12-27  28,645.26  28,675.34  28,701.66  28,608.98  184.93M    0.08%\n2019-12-26  28,621.39  28,539.46  28,624.10  28,535.15  155.97M    0.37%\n2019-12-24  28,515.45  28,572.57  28,576.80  28,503.21   95.29M   -0.13%",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Close</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Volume</th>\n      <th>Change %</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-12-31</th>\n      <td>28,538.44</td>\n      <td>28,414.64</td>\n      <td>28,547.35</td>\n      <td>28,376.49</td>\n      <td>193.34M</td>\n      <td>0.27%</td>\n    </tr>\n    <tr>\n      <th>2019-12-30</th>\n      <td>28,462.14</td>\n      <td>28,654.76</td>\n      <td>28,664.69</td>\n      <td>28,428.98</td>\n      <td>185.07M</td>\n      <td>-0.64%</td>\n    </tr>\n    <tr>\n      <th>2019-12-27</th>\n      <td>28,645.26</td>\n      <td>28,675.34</td>\n      <td>28,701.66</td>\n      <td>28,608.98</td>\n      <td>184.93M</td>\n      <td>0.08%</td>\n    </tr>\n    <tr>\n      <th>2019-12-26</th>\n      <td>28,621.39</td>\n      <td>28,539.46</td>\n      <td>28,624.10</td>\n      <td>28,535.15</td>\n      <td>155.97M</td>\n      <td>0.37%</td>\n    </tr>\n    <tr>\n      <th>2019-12-24</th>\n      <td>28,515.45</td>\n      <td>28,572.57</td>\n      <td>28,576.80</td>\n      <td>28,503.21</td>\n      <td>95.29M</td>\n      <td>-0.13%</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Storing the data in a dataframe and renaming Price and Vol to Close and Volume\n",
    "df_raw = pd.read_csv(\"./dataset/doj_historical.csv\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "df_raw.rename(columns = {\"Price\" : \"Close\", \"Vol.\": \"Volume\" }, inplace = True)\n",
    "# Evaluating the columns and the content of the dataframe\n",
    "df_raw.head(5)\n",
    "\n",
    "# We have six original columns and we'll transform them to get more dimensions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df_raw.drop(\"Change %\", axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Close', 'Open', 'High', 'Low', 'Volume'], dtype='object')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Close     2766\nOpen      2766\nHigh      2766\nLow       2766\nVolume    2766\ndtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of samples (each row is a day in the stock market)\n",
    "df_raw.count(axis = 0)\n",
    "# We have 2766 days worth of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 2766)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dimensions of our raw dataset\n",
    "len(df_raw.columns), len(df_raw.values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows with '-' symbol:\n",
      "                Close       Open       High        Low Volume\n",
      "Date                                                         \n",
      "2010-05-13  10,782.95  10,896.61  10,952.84  10,752.72      -\n",
      "2010-05-12  10,896.91  10,742.15  10,941.88  10,725.81      -\n",
      "2010-05-11  10,748.26  10,780.00  10,888.30  10,653.71      -\n",
      "2010-05-10  10,785.14  10,386.18  10,880.14  10,386.18      -\n",
      "2010-05-07  10,380.43  10,519.42  10,622.27  10,221.50      -\n",
      "...               ...        ...        ...        ...    ...\n",
      "2009-01-09   8,599.18   8,738.80   8,800.45   8,541.75      -\n",
      "2009-01-08   8,742.46   8,769.94   8,807.14   8,593.52      -\n",
      "2009-01-07   8,769.70   8,996.94   8,996.94   8,690.45      -\n",
      "2009-01-06   9,015.10   8,954.57   9,175.19   8,868.07      -\n",
      "2009-01-05   8,952.89   9,027.13   9,093.47   8,841.70      -\n",
      "\n",
      "[342 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find rows with '-' in any of the columns\n",
    "filtered_df = df_raw[df_raw.apply(lambda row: row.str.contains('-')).any\n",
    "(axis=1)]\n",
    "print(\"\\nRows with '-' symbol:\")\n",
    "print(filtered_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There seems to be problematic input that caused the following error when\n",
    "transforming the data into floats:\n",
    "Error: ValueError: could not convert string to float: '-'\n",
    "Solution:\n",
    "1) develop a lambda function to find and replace the values:\n",
    "2) use a technique to fill these values with either the mean, the mode or the\n",
    " medium - Simple imputer\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Date\n2019-12-31    193340.0\n2019-12-30    185070.0\n2019-12-27    184930.0\n2019-12-26    155970.0\n2019-12-24     95290.0\n                ...   \n2009-01-09         NaN\n2009-01-08         NaN\n2009-01-07         NaN\n2009-01-06         NaN\n2009-01-05         NaN\nName: Volume, Length: 2766, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll delete the M for all values and multiply for 1000,\n",
    "# All other values that contain \"-\", we'll replace them with nan\n",
    "df_raw['Volume'] = df_raw['Volume'].apply(lambda x: 1000 * float(x.replace(\"M\",\n",
    "                                                                        \"\"))\n",
    "if x != \"-\" else float(\"nan\"))\n",
    "\n",
    "df_raw['Volume']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Date\n2019-12-31    193340.0\n2019-12-30    185070.0\n2019-12-27    184930.0\n2019-12-26    155970.0\n2019-12-24     95290.0\n                ...   \n2009-01-09         NaN\n2009-01-08         NaN\n2009-01-07         NaN\n2009-01-06         NaN\n2009-01-05         NaN\nName: Volume, Length: 2766, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use the SimpleImputer to convert all missing values from nan to the mean of\n",
    "# all other rows\n",
    "volume_transformed = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "volume_transformed.fit(df_raw['Volume'].values.reshape(-1, 1))\n",
    "volume_transformed.transform(df_raw['Volume'].values.reshape(-1, 1))\n",
    "\n",
    "df_raw['Volume']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\52556\\AppData\\Local\\Temp\\ipykernel_30148\\362144960.py:13: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df_raw.iloc[:,:-1] = df_raw.iloc[:,:-1].applymap(remove_commas)\n"
     ]
    }
   ],
   "source": [
    "# Making sure that all values are of type float since there are some\n",
    "# characters (commas, suffixes) that will stop us from using the functions\n",
    "def remove_commas(value):\n",
    "    \"\"\"\n",
    "    This function converts strings in our rows into floats. It also removes\n",
    "    commas and the M suffix in the column for volume.\n",
    "    @param value: str, The value in the current row\n",
    "    @return: float, a clean version of the original data\n",
    "    \"\"\"\n",
    "    return float(value.replace(\",\", \"\"))\n",
    "\n",
    "# Applying the custom function to all elements in the dataframe\n",
    "df_raw.iloc[:,:-1] = df_raw.iloc[:,:-1].applymap(remove_commas)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Using Pandas to generate features\n",
    "* We'll implement a series of functions that directly create features from\n",
    "the original six financial variables.\n",
    "* A main function will then call these sub-functions to generate a new\n",
    "dataset with a total of 37 columns.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def add_original_feature(df, df_new):\n",
    "    \"\"\"\n",
    "    Generate features for a stock/index on historical price and performance.\n",
    "    It uses pandas functions to generate new columns. Ex: shift() and rolling().\n",
    "    @param df: dataframe with columns: \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\"\n",
    "    @param df_new: dataframe with new features based on the original dataset.\n",
    "    \"\"\"\n",
    "    # Getting the 6 original features\n",
    "    df_new['open'] = df ['Open']\n",
    "    df_new['open_1'] = df['Open'].shift(1)\n",
    "    df_new['close_1'] = df['Close'].shift(1)\n",
    "    df_new['high_1'] = df['High'].shift(1)\n",
    "    df_new['low_1'] = df['Low'].shift(1)\n",
    "    df_new['volume_1'] = df['Volume'].shift(1)\n",
    "\n",
    "def add_avg_price(df, df_new):\n",
    "    \"\"\"\n",
    "    A sub-function that generates six features related to average close prices:\n",
    "    @param df: dataframe with columns: \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\"\n",
    "    @param df_new: dataframe with 6 new features based on the original dataset.\n",
    "    \"\"\"\n",
    "    # We use the rolling() function to create a window and then apply a\n",
    "    # function to the specified number of rows. Essentially, we're creating 3\n",
    "    # new columns with the average prices for a week, a month and a year\n",
    "    df_new['avg_price_5'] = df['Close'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_price_30'] = df['Close'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_price_365'] = df['Close'].rolling(252).mean().shift(1)\n",
    "\n",
    "    # We create new columns that will store the ratio of change between a\n",
    "    # week/month, week/year, month/year\n",
    "    df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n",
    "    df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n",
    "    df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']\n",
    "\n",
    "def add_avg_volume(df, df_new):\n",
    "    \"\"\"\n",
    "    A sub-function that generates six features related to average volumes:\n",
    "    @param df: dataframe with columns: \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\"\n",
    "    @param df_new: dataframe with 6 new features based on the original dataset.\n",
    "    \"\"\"\n",
    "    # We create three new columns by averaging the change rate of 5, 21 and\n",
    "    # 252 trading days (week, month, year).\n",
    "    df_new['avg_volume_5'] = df['Volume'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_volume_30'] =   df['Volume'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_volume_365'] = df['Volume'].rolling(252).mean().shift(1)\n",
    "\n",
    "    # And now we create three new features by getting the ratio of volume\n",
    "    # change between week/month, week/year, month /year\n",
    "    df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n",
    "    df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n",
    "    df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n",
    "\n",
    "def add_std_price(df, df_new):\n",
    "    \"\"\"\n",
    "    A sub-function that calculates the standard deviation for the\n",
    "    price-related features:\n",
    "    @param df: dataframe with columns: \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\"\n",
    "    @param df_new: dataframe with 6 new features based on the original dataset.\n",
    "    \"\"\"\n",
    "    # Using pandas rolling() function, we get the a window for 5, 21 and 252\n",
    "    # trading days, then we apply the std() function and shift 1 row below\n",
    "    df_new['std_price_5'] = df['Close'].rolling(5).std().shift(1)\n",
    "    df_new['std_price_30'] = df['Close'].rolling(21).std().shift(1)\n",
    "    df_new['std_price_365'] = df['Close'].rolling(252).std().shift(1)\n",
    "    # Similarly, we create features for the ratio between the newly\n",
    "    # calculated standard deviations for week/year, week/month and so on\n",
    "    df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n",
    "    df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n",
    "    df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']\n",
    "\n",
    "def add_std_volume(df, df_new):\n",
    "    \"\"\"\n",
    "    A sub-function that calculates the standard deviation for the\n",
    "    volume-based standard deviation features:\n",
    "    @param df: dataframe with columns: \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\"\n",
    "    @param df_new: dataframe with 6 new features based on the original dataset.\n",
    "    \"\"\"\n",
    "    # Using pandas rolling() function, we get the a window for 5, 21 and 252\n",
    "    # trading days, then we apply the std() function and shift 1 row below\n",
    "    df_new['std_volume_5'] = df['Volume'].rolling(5).std().shift(1)\n",
    "    df_new['std_volume_30'] = df['Volume'].rolling(21).std().shift(1)\n",
    "    df_new['std_volume_365'] = df['Volume'].rolling(252).std().shift(1)\n",
    "    # Similarly, we create features for the ratio between the newly\n",
    "    # calculated standard deviations for week/year, week/month and so on\n",
    "    df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n",
    "    df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']\n",
    "    df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']\n",
    "\n",
    "def add_return_feature(df, df_new):\n",
    "    \"\"\"\n",
    "    This function calculates the return for the stock. That is the value of\n",
    "    the current Closing price minus the Closing price of the previous day\n",
    "    over the price in the previous day. This function gets the\n",
    "    return value for the previous day, the past week, past month and past\n",
    "    year. It also calculates the moving average. In total, we get 7 new features\n",
    "    @param df: dataframe with columns: \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\"\n",
    "    @param df_new: dataframe with 7 new features based on the original dataset.\n",
    "    \"\"\"\n",
    "    # Calculating the return for the previous day, the past week, past month\n",
    "    # and past year\n",
    "    df_new['return_1'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1).shift(1))\n",
    "    df_new['return_5'] = ((df['Close'] - df['Close'].shift(5)) / df['Close'].shift(5)).shift(1)\n",
    "    df_new['return_30'] = ((df['Close'] - df['Close'].shift(21)) / df['Close'].shift(21)).shift(1)\n",
    "    df_new['return_365'] = ((df['Close'] - df['Close'].shift(252)) / df['Close'].shift(252)).shift(1)\n",
    "\n",
    "    # Now calculating the moving average for a week, a month and a year\n",
    "    df_new['moving_avg_5'] = df_new['return_1'].rolling(5).mean().shift(1)\n",
    "    df_new['moving_avg_30'] = df_new['return_1'].rolling(21).mean().shift(1)\n",
    "    df_new['moving_avg_365'] = df_new['return_1'].rolling(252).mean().shift(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Putting all the sub-functions together.\n",
    "* Note that the window sizes here are 5, 21, and 252, instead of 7, 30, and 365 representing the weekly, monthly, and yearly window. This is because there are 252 (rounded) trading days in a year, 21 trading days in a month, and 5 in a week."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Now we create a main function that calls all preceding sub-functions and\n",
    "# creates a new dataframe with 31 new features\n",
    "def generate_features(df):\n",
    "    \"\"\"\n",
    "    Generate features for a stock/index based on historical price and\n",
    "    performance\n",
    "    @param df: dataframe with columns \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\"\n",
    "    @return: dataframe, data set with 31 new features\n",
    "    \"\"\"\n",
    "    df_new = pd.DataFrame()\n",
    "\n",
    "    # Getting the 6 original features:\n",
    "    add_original_feature(df, df_new)\n",
    "\n",
    "    # Add the 31 new features\n",
    "    add_avg_price(df, df_new)\n",
    "    add_avg_volume(df, df_new)\n",
    "    add_std_price(df, df_new)\n",
    "    add_std_volume(df, df_new)\n",
    "    add_return_feature(df, df_new)\n",
    "\n",
    "    # Adding a new column, the target (we'll predict a stock price)\n",
    "    # dropna : 0, or ‘index’ : Drop rows which contain missing values.\n",
    "    df_new['close'] = df['Close']\n",
    "    df_new = df_new.dropna(axis = 0)\n",
    "    return df_new\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 2171\n",
      "                open    open_1   close_1    high_1     low_1  volume_1  \\\n",
      "Date                                                                     \n",
      "2018-12-27  22629.06  23213.61  23062.40  23381.88  22981.33  336510.0   \n",
      "2018-12-26  21857.73  22629.06  23138.82  23138.89  22267.42  407940.0   \n",
      "2018-12-24  22317.28  21857.73  22878.45  22878.92  21712.53  433080.0   \n",
      "2018-12-21  22871.74  22317.28  21792.20  22339.87  21792.20  308420.0   \n",
      "2018-12-20  23224.12  22871.74  22445.37  23254.59  22396.34  900510.0   \n",
      "\n",
      "            avg_price_5  avg_price_30  avg_price_365  ratio_avg_price_5_30  \\\n",
      "Date                                                                         \n",
      "2018-12-27    23171.096     23985.192      26337.481                 0.966   \n",
      "2018-12-26    23112.228     23916.566      26315.630                 0.966   \n",
      "2018-12-24    23150.674     23838.006      26292.841                 0.971   \n",
      "2018-12-21    22839.866     23697.768      26266.161                 0.964   \n",
      "2018-12-20    22663.448     23597.393      26241.930                 0.960   \n",
      "\n",
      "            ...  ratio_std_volume_5_365  ratio_std_volume_30_365  return_1  \\\n",
      "Date        ...                                                              \n",
      "2018-12-27  ...                   0.839                    0.597     0.003   \n",
      "2018-12-26  ...                   0.873                    0.649    -0.011   \n",
      "2018-12-24  ...                   0.910                    0.724    -0.047   \n",
      "2018-12-21  ...                   0.957                    0.727     0.029   \n",
      "2018-12-20  ...                   3.168                    1.734     0.019   \n",
      "\n",
      "            return_5  return_30  return_365  moving_avg_5  moving_avg_30  \\\n",
      "Date                                                                       \n",
      "2018-12-27    -0.020     -0.078      -0.190        -0.004         -0.004   \n",
      "2018-12-26    -0.013     -0.059      -0.192        -0.002         -0.003   \n",
      "2018-12-24     0.008     -0.067      -0.201         0.002         -0.003   \n",
      "2018-12-21    -0.067     -0.119      -0.236        -0.013         -0.006   \n",
      "2018-12-20    -0.038     -0.086      -0.214        -0.008         -0.004   \n",
      "\n",
      "            moving_avg_365     close  \n",
      "Date                                  \n",
      "2018-12-27          -0.001  23138.82  \n",
      "2018-12-26          -0.001  22878.45  \n",
      "2018-12-24          -0.001  21792.20  \n",
      "2018-12-21          -0.001  22445.37  \n",
      "2018-12-20          -0.001  22859.60  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating a new, enhanced dataset:\n",
    "data = generate_features(df_raw)\n",
    "# The dimensions of our new dataset\n",
    "print(len(data.columns), len(data.values))\n",
    "\n",
    "# Taking a look at what the data with the new features looks like\n",
    "print(data.round(decimals=3).head(5))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
