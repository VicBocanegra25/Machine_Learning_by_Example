{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Regression Trees\n",
    "* We'll build a regression tree model from scratch using functions to find\n",
    "the split that minimizes the MSE and then we'll average the leafs instead of\n",
    "counting the number of classes (like in classification).\n",
    "* We'll use it on a toy dataset and then we'll build a regression tree model\n",
    "using scikit-learn on another notebook.\n",
    "* The quality of the splitting point is measured by the weighted MSE of two\n",
    "children (variance of all target values). The samller the weighted MSE, the\n",
    "better the split.\n",
    "![House_dataset](./dataset/toy_dataset_house_prices.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Define the MSE and weighted MSE functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# This calculates the single variance (MSE) for the targets\n",
    "def mse(targets):\n",
    "    # When the set is empty, the MSE is 0\n",
    "    if targets.size == 0:\n",
    "        return 0\n",
    "    # Otherwise, return the variance\n",
    "    return np.var(targets)\n",
    "\n",
    "# Define the weighted MSE after a split in a node\n",
    "def weighted_mse(groups):\n",
    "    \"\"\"\n",
    "    Calculate the weighted MSE of children after a split\n",
    "    \"\"\"\n",
    "    total = sum(len(group) for group in groups)\n",
    "    weighted_sum = 0.0\n",
    "\n",
    "    # Iterating on each group and using the mse function declared before\n",
    "    for group in groups:\n",
    "        weighted_sum += len(group) / float(total) * mse(group)\n",
    "    return weighted_sum\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.6667\n",
      "weighted mse: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Testing the functions:\n",
    "print(f\"mse: {mse(np.array([1, 2, 3])):.4f}\")\n",
    "print(f\"weighted mse: {weighted_mse([np.array([1, 2, 3]), np.array([1, 2])]):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Building the splitting node function.\n",
    "* To build the house price regressio tree, we exhaust all possible pairs of\n",
    "feature and value and we compute the corresponding MSE.\n",
    "* Once we're satisfied with the nodes, we calculate the averaged target price\n",
    " for each leaf\n",
    "![house_split](dataset/toy_dataset_house_prices_splitting_nodes.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Node splitting utility function\n",
    "def split_node(X, y, index, value):\n",
    "    \"\"\"\n",
    "    Split data set X, y based on a feature and a value\n",
    "    @param index: index of the feature used for splitting\n",
    "    @param value: value of the feature used for splitting\n",
    "    @return: left and right child, a child is in the format of [X, y]\n",
    "    \"\"\"\n",
    "    x_index = X[:, index]\n",
    "    # If the feature is numerical, apply a mask based on value\n",
    "    if type(X[0, index]) in [int, float]:\n",
    "        mask = x_index >= value\n",
    "    # If this feature is categorical:\n",
    "    else:\n",
    "        mask = x_index == value\n",
    "    # split into left and right child\n",
    "    left = [X[~mask, :], y[~mask]]\n",
    "    right = [X[mask, :], y[mask]]\n",
    "    return left, right\n",
    "\n",
    "# Define the greedy search function, trying out all possible splits and\n",
    "# returning the one with the least weighted MSE\n",
    "\n",
    "def get_best_split(X, y):\n",
    "    \"\"\"\n",
    "    Obtain the best splitting point and resulting children for the data set X, y\n",
    "    @return: {index: index of the feature, value: feature value, children: left and right children}\n",
    "    \"\"\"\n",
    "    # Using placeholders for the best index, value, score and children\n",
    "    best_index, best_value, best_score, children = None, None, 1e10, None\n",
    "\n",
    "    for index in range(len(X[0])):\n",
    "        # Trying out each column\n",
    "        for value in np.sort(np.unique(X[:, index])):\n",
    "            # Calling the split_node to get left and right children\n",
    "            groups = split_node(X, y, index, value)\n",
    "            # Getting the weighted_mse from the children (left, right)\n",
    "            evaluation_metric = weighted_mse([groups[0][1], groups[1][1]])\n",
    "\n",
    "            # If we find a best score, we update all values\n",
    "            if evaluation_metric < best_score:\n",
    "                best_index, best_values, best_score, children = index, value,\\\n",
    "                                                                evaluation_metric, groups\n",
    "    return {'index': best_index, 'value': best_value,\n",
    "            'children': children}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Building the recursive function:\n",
    "* Our final function is called split(). The purpose is to link it all together.\n",
    "* It checks whether any stopping criteria are met and assigns the leaf node if so, or proceeds with further separation otherwise:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def get_leaf(targets):\n",
    "    # Obtain the leaf as the mean of the targets\n",
    "    return np.mean(targets)\n",
    "\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    # Split children of a node to construct new nodes or assign them terminals\n",
    "    # node: dictionary with children information\n",
    "    # max_depth: maximal depth of the tree\n",
    "    # min_size: minimal samples required to further split a child\n",
    "    # depth: current depth of the node\n",
    "\n",
    "    # Splitting node into left and right children\n",
    "    left, right = node['children']\n",
    "    # Delete the 'children' key from the node dictionary\n",
    "    del(node['children'])\n",
    "\n",
    "    # If left child has no samples, set the right child as the leaf node and return\n",
    "    if left[1].size == 0:\n",
    "        node['right'] = get_leaf(right[1])\n",
    "        return\n",
    "\n",
    "    # If right child has no samples, set the left child as the leaf node and return\n",
    "    if right[1].size == 0:\n",
    "        node['left'] = get_leaf(left[1])\n",
    "        return\n",
    "\n",
    "    # Check if the current depth exceeds the maximal depth\n",
    "    if depth >= max_depth:\n",
    "        # Set both left and right children as leaf nodes and return\n",
    "        node['left'], node['right'] = get_leaf(left[1]), get_leaf(right[1])\n",
    "        return\n",
    "\n",
    "    # Check if the left child has enough samples\n",
    "    if left[1].size <= min_size:\n",
    "        # If not, set the left child as a leaf node\n",
    "        node['left'] = get_leaf(left[1])\n",
    "    else:\n",
    "        # If it has enough samples, further split the left child\n",
    "        result = get_best_split(left[0], left[1])\n",
    "        result_left, result_right = result['children']\n",
    "\n",
    "        # Handle the cases where one of the result's children has no samples\n",
    "        if result_left[1].size == 0:\n",
    "            node['left'] = get_leaf(result_right[1])\n",
    "        elif result_right[1].size == 0:\n",
    "            node['left'] = get_leaf(result_left[1])\n",
    "        else:\n",
    "            node['left'] = result\n",
    "            # Recursively call the split function for the left child\n",
    "            split(node['left'], max_depth, min_size, depth + 1)\n",
    "\n",
    "    # Check if the right child has enough samples\n",
    "    if right[1].size <= min_size:\n",
    "        # If not, set the right child as a leaf node\n",
    "        node['right'] = get_leaf(right[1])\n",
    "    else:\n",
    "        # If it has enough samples, further split the right child\n",
    "        result = get_best_split(right[0], right[1])\n",
    "        result_left, result_right = result['children']\n",
    "\n",
    "        # Handle the cases where one of the result's children has no samples\n",
    "        if result_left[1].size == 0:\n",
    "            node['right'] = get_leaf(result_right[1])\n",
    "        elif result_right[1].size == 0:\n",
    "            node['right'] = get_leaf(result_left[1])\n",
    "        else:\n",
    "            node['right'] = result\n",
    "            # Recursively call the split function for the right child\n",
    "            split(node['right'], max_depth, min_size, depth + 1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# The entry point of the regression tree construction is as follows:\n",
    "\n",
    "def train_regression_tree(X_train, y_train, max_depth, min_size):\n",
    "    # Getting a root node (the one with the smallest MSE)\n",
    "    root = get_best_split(X_train, y_train)\n",
    "    # Calling the recursive function to get the best tree\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final step: Testing the functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'index': 0,\n 'value': None,\n 'left': {'index': 1, 'value': None, 'left': 400.0, 'right': 650.0},\n 'right': 750.0}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([['semi', 3],\n",
    "                    ['detached', 2],\n",
    "                    ['detached', 3],\n",
    "                    ['semi', 2],\n",
    "                    ['semi', 4]], dtype=object)\n",
    "y_train = np.array([600, 700, 800, 400, 700])\n",
    "\n",
    "tree = train_regression_tree(X_train, y_train, 2, 2)\n",
    "tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- X1 is not None\n",
      " |- X2 is not None\n",
      "  [400.0]\n",
      " |- X2 is None\n",
      "  [650.0]\n",
      "|- X1 is None\n",
      " [750.0]\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the tree (an auxiliary function to compare our tree with the\n",
    "# one drawn by hand\n",
    "CONDITION = {'numerical': {'yes': '>=', 'no': '<'},\n",
    "              'categorical': {'yes': 'is', 'no': 'is not'}}\n",
    "def visualize_tree(node, depth=0):\n",
    "     if isinstance(node, dict):\n",
    "         if type(node['value']) in [int, float]:\n",
    "             condition = CONDITION['numerical']\n",
    "         else:\n",
    "             condition = CONDITION['categorical']\n",
    "         print('{}|- X{} {} {}'.format(depth * ' ',\n",
    "                  node['index'] + 1, condition['no'],\n",
    "                  node['value']))\n",
    "         if 'left' in node:\n",
    "             visualize_tree(node['left'], depth + 1)\n",
    "         print('{}|- X{} {} {}'.format(depth * ' ',\n",
    "                 node['index'] + 1, condition['yes'],\n",
    "                 node['value']))\n",
    "         if 'right' in node:\n",
    "             visualize_tree(node['right'], depth + 1)\n",
    "     else:\n",
    "         print('{}[{}]'.format(depth * ' ', node))\n",
    "visualize_tree(tree)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
