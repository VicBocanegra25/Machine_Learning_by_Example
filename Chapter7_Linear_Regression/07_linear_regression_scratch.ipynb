{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression from scratch\n",
    "* We'll implement a linear regression model from scratch\n",
    "* It will use a defined learning rate and gradient descent to update the\n",
    "values on each iteration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_prediction(X, weights):\n",
    "    \"\"\"\n",
    "    Compute the prediction y_hat based on the current weights\n",
    "    @param X: dataframe, the features of our dataset\n",
    "    @param weights: float, a multiplier vector that tries to minimize the MSE\n",
    "     between the real target value and the predicted value\n",
    "    @return: float, the predictions based on our current weights\n",
    "    \"\"\"\n",
    "    # We use the dot product X.w\n",
    "    predictions = np.dot(X, weights)\n",
    "    return predictions\n",
    "\n",
    "def update_weights_gd(X_train, y_train, weights, learning_rate):\n",
    "    \"\"\"\n",
    "    The function updating the weight, w, with one step in a gradient descent\n",
    "    manner\n",
    "\n",
    "    @param X_train: dataframe: The training features\n",
    "    @param y_train: dataframe: The target values\n",
    "    @param weights: float, a multiplier vector that tries to minimize the MSE\n",
    "     between the real target value and the predicted value\n",
    "    @param learning_rate: The learning rate, usually very small, it will\n",
    "    provide a changing value for weights on each iteration\n",
    "    @return: updated weights\n",
    "    \"\"\"\n",
    "\n",
    "    # We call the function to compute the current predicted values\n",
    "    predictions = compute_prediction(X_train, weights)\n",
    "    # The derivate of our weights\n",
    "    weights_delta = np.dot(X_train.T, y_train - predictions)\n",
    "    # The number of training examples. The purpose of m in this code is to normalize the weight update step during gradient descent.\n",
    "    m = y_train.shape[0]\n",
    "    # Updating weights.\n",
    "    weights += learning_rate / float(m) * weights_delta\n",
    "    return weights\n",
    "\n",
    "def compute_cost(X, y, weights):\n",
    "    \"\"\"\n",
    "     the function that calculates the cost J(w)\n",
    "    @param X: dataframe: The feature vector X.\n",
    "    @param y: dataframe: The target values\n",
    "    @param weights: The current weights for our model.\n",
    "    @return: float: the cost (Mean Squared Error)\n",
    "    \"\"\"\n",
    "    # Predicting with the current weights\n",
    "    predictions = compute_prediction(X, weights)\n",
    "    # The cost is the mean squared error of the predicted values - the actual\n",
    "    # target value\n",
    "    cost = np.mean((predictions - y) ** 2 / 2.0)\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Putting it all together in a main iterative function:\n",
    "Now, put all functions together with a model training function by performing the following tasks:\n",
    "\n",
    "Update the weight vector in each iteration\n",
    "Print out the current cost for every 100 (or it can be any number) iterations to ensure cost is decreasing and things are on the right track"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def train_linear_regresion(X_train, y_train, max_iter, learning_rate,\n",
    "                           fit_interceot = False):\n",
    "    \"\"\"\n",
    "    Train a linear regression model with gradient descent, and return the\n",
    "    trained model\n",
    "    @param X_train: dataframe, the train feature vector\n",
    "    @param y_Train: dataframe, the train target values\n",
    "    @param max_iter: int, the maximum number of iterations, it's a stopping\n",
    "    condition\n",
    "    @param learning_rate: float, the learning change rate we'll use to update\n",
    "     the weights\n",
    "    @param fit_interceot: flaot, the initial bias (False by default)\n",
    "    @return: dataframe, weights: The updated final weights that we'll use to\n",
    "    make predictions\n",
    "    \"\"\"\n",
    "    if fit_interceot:\n",
    "        # If the bias exists, we need to add one more value to each sample\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train = np.hstack((intercept, X_train))\n",
    "    # Our starting weights are initialized as 0s\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        weights = update_weights_gd(X_train, y_train, weights, learning_rate)\n",
    "        # Check out the cost for every 100 iterations\n",
    "        if iteration % 100 == 0:\n",
    "            print(f\"The current loss: {compute_cost(X_train, y_train, weights)}\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "def predict(X, weights):\n",
    "    \"\"\"\n",
    "    predict the results of new input values using the trained model\n",
    "    @param X: dataframe: Features\n",
    "    @param weights: dataframe: current weights\n",
    "    @return: dataframe or array: Predicted values based on the model\n",
    "    \"\"\"\n",
    "    if X.shape[1] == weights.shape[0] - 1:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "    return compute_prediction(X, weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current loss: 5.680896928000001\n",
      "The current loss: 0.07367346938775511\n",
      "The current loss: 0.07367346938775512\n",
      "The current loss: 0.07367346938775512\n",
      "The current loss: 0.07367346938775512\n",
      "The current loss: 0.07367346938775512\n",
      "The current loss: 0.07367346938775512\n",
      "The current loss: 0.07367346938775512\n",
      "The current loss: 0.07367346938775512\n",
      "The current loss: 0.07367346938775512\n"
     ]
    }
   ],
   "source": [
    "# Testing the functions:\n",
    "X_train = np.array([[6], [2], [3], [4], [1], [5], [2], [6], [4], [7]])\n",
    "y_train = np.array([5.5, 1.6, 2.2, 3.7, 0.8, 5.2, 1.5, 5.3, 4.4, 6.8])\n",
    "\n",
    "# Training a model with 1000 iterationons and a learning rate of 0.01\n",
    "weights = train_linear_regresion(X_train, y_train, max_iter = 1000,\n",
    "                                 learning_rate = 0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the model's performance on new samples\n",
    "import matplotlib.pyplot as plt\n",
    "X_test = np.array([[1.3], [3.5], [5.2], [2.8]])\n",
    "predictions = predict(X_test, weights)\n",
    "\n",
    "# Plotting both the train values and the new predicted values\n",
    "plt.scatter(X_train[:, 0], y_train, marker = \"o\", c = \"b\")\n",
    "plt.scatter(X_test[:, 0], predictions, marker = \"*\", c = \"k\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Trying our model on the diabetes dataset from scikit-learn\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "print(diabetes.data.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# We'll only get 30 samples for testing\n",
    "test_samples = 30\n",
    "\n",
    "# Declaring the training data\n",
    "X_train_diabetes = diabetes.data[:-test_samples, :]\n",
    "y_train_diabetes = diabetes.target[:-test_samples]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current loss: 2960.123025607216\n",
      "The current loss: 1984.748663254882\n",
      "The current loss: 1729.7769635921989\n",
      "The current loss: 1627.6348119343263\n",
      "The current loss: 1572.763273052353\n",
      "The current loss: 1539.554802043756\n",
      "The current loss: 1518.6181097259152\n",
      "The current loss: 1505.1916919461312\n",
      "The current loss: 1496.4882691586809\n",
      "The current loss: 1490.7927148484966\n",
      "The current loss: 1487.0293572901583\n",
      "The current loss: 1484.516650020924\n",
      "The current loss: 1482.8194344074193\n",
      "The current loss: 1481.6579404201677\n",
      "The current loss: 1480.8510951067901\n",
      "The current loss: 1480.280921685538\n",
      "The current loss: 1479.870031213809\n",
      "The current loss: 1479.5673033510566\n",
      "The current loss: 1479.3387231207394\n",
      "The current loss: 1479.1614836837496\n",
      "The current loss: 1479.0201696937393\n",
      "The current loss: 1478.9042732451073\n",
      "The current loss: 1478.8065678119995\n",
      "The current loss: 1478.7220374658161\n",
      "The current loss: 1478.6471673310045\n",
      "The current loss: 1478.57947029736\n",
      "The current loss: 1478.5171691036435\n",
      "The current loss: 1478.4589811941237\n",
      "The current loss: 1478.4039719757411\n",
      "The current loss: 1478.3514538988786\n",
      "The current loss: 1478.3009164521106\n",
      "The current loss: 1478.251977168085\n",
      "The current loss: 1478.204347022648\n",
      "The current loss: 1478.1578057754248\n",
      "The current loss: 1478.1121842360594\n",
      "The current loss: 1478.0673513977845\n",
      "The current loss: 1478.0232050223478\n",
      "The current loss: 1477.9796646941397\n",
      "The current loss: 1477.9366666564356\n",
      "The current loss: 1477.8941599449038\n",
      "The current loss: 1477.8521034731898\n",
      "The current loss: 1477.8104638227055\n",
      "The current loss: 1477.7692135570749\n",
      "The current loss: 1477.728329930129\n",
      "The current loss: 1477.6877938909208\n",
      "The current loss: 1477.647589314213\n",
      "The current loss: 1477.6077024029762\n",
      "The current loss: 1477.5681212227464\n",
      "The current loss: 1477.5288353374858\n",
      "The current loss: 1477.4898355238697\n"
     ]
    }
   ],
   "source": [
    "# Train a linear regression model with 5000 iterations, at a learning rate of\n",
    "# 1\n",
    "weights = train_linear_regresion(X_train_diabetes, y_train_diabetes, max_iter\n",
    "= 5000, learning_rate = 1, fit_interceot = True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our predicted values\n",
      ": [232.22192119 123.87532386 166.12297497 170.23855082 228.12523411\n",
      " 154.9570854  101.09011561  87.33479691 143.68827095 190.29424697\n",
      " 198.00696804 149.63068784 169.56215468 109.01832867 161.97943375\n",
      " 133.00757288 260.18431805 101.52516612 115.76691141 120.73229914\n",
      " 219.62761982  62.21080727 136.29855757 122.27895603  55.14532638\n",
      " 191.50289376 105.68864904 126.26137526 208.99754096  47.66481183]\n",
      "The real target values\n",
      ": [261. 113. 131. 174. 257.  55.  84.  42. 146. 212. 233.  91. 111. 152.\n",
      " 120.  67. 310.  94. 183.  66. 173.  72.  49.  64.  48. 178. 104. 132.\n",
      " 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "# Making predictions:\n",
    "X_test_diabetes = diabetes.data[-test_samples:, :]\n",
    "y_test_diabetes = diabetes.target[-test_samples:]\n",
    "predictions  = predict(X_test_diabetes, weights)\n",
    "\n",
    "print(f\"Our predicted values\\n: {predictions}\")\n",
    "\n",
    "print(f\"The real target values\\n: {y_test_diabetes}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
