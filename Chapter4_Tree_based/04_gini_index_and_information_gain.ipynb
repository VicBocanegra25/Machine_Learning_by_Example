{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics for measuring a split.\n",
    "* We'll develop functions to compute the following metrics to measure the\n",
    "quality of a separation\n",
    "1. Gini impurity index: A lower Gini impurity index indicates a purer dataset.\n",
    "2. Information gain (entropy): Measures the improvement of purity after\n",
    "splitting. In other words, the reduction of uncertainty due to a split.\n",
    "3. Entropy: Is a probabilistic measure of uncertainty. Lower entropy implies\n",
    "a purer dataset with less ambiguity.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gini impurity index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "# Programming a function to calculate the gini impurity index\n",
    "import numpy as np\n",
    "\n",
    "def gini_impurity(labels):\n",
    "    \"\"\"\n",
    "    Calculate the Gini impurity of a list of labels.\n",
    "\n",
    "    :param labels: List of labels in a dataset.\n",
    "    :return: Gini impurity index.\n",
    "    \"\"\"\n",
    "    # When the set is empty, it is also pure\n",
    "    if not labels:\n",
    "        return 0\n",
    "    # Count the occurrences of each label\n",
    "    counts = np.unique(labels, return_counts=True)[1]\n",
    "    # Calculate the fractions of each label's occurrences\n",
    "    fractions = counts / float(len(labels))\n",
    "    # Compute the Gini impurity index\n",
    "    return 1 - np.sum(fractions ** 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4082\n"
     ]
    }
   ],
   "source": [
    "# Testing out some examples:\n",
    "print(f\"{gini_impurity([1, 1, 0, 1, 1, 0, 1]):.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000\n"
     ]
    }
   ],
   "source": [
    "print(f'{gini_impurity([1, 1, 0, 1, 0, 0]):.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Information gain and Entropy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "# Calculating the entropy of a given set\n",
    "def entropy(labels):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a list of labels.\n",
    "\n",
    "    :param labels: List of labels in a dataset.\n",
    "    :return: Entropy of the dataset.\n",
    "    \"\"\"\n",
    "    # When the set is empty, it has no entropy\n",
    "    if not labels:\n",
    "        return 0\n",
    "    # Count the occurrences of each label\n",
    "    counts = np.unique(labels, return_counts=True)[1]\n",
    "    # Calculate the fractions of each label's occurrences\n",
    "    fractions = counts / float(len(labels))\n",
    "    # Compute the entropy using the fractions and log base 2\n",
    "    return - np.sum(fractions * np.log2(fractions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8631\n"
     ]
    }
   ],
   "source": [
    "# Checking some examples:\n",
    "print(f\"{entropy([1, 1, 0, 1, 1, 0, 1]):.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9710\n"
     ]
    }
   ],
   "source": [
    "print(f'{entropy([1, 1, 0, 1, 0]):.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f'{entropy([1, 1, 1, 1]):.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# Define a dictionary to map criterion names to their respective functions\n",
    "criterion_function = {'gini': gini_impurity, 'entropy': entropy}\n",
    "\n",
    "def weighted_impurity(groups, criterion='gini'):\n",
    "    \"\"\"\n",
    "    Calculate the weighted impurity of children after a split.\n",
    "\n",
    "    :param groups: List of children, and a child consists of a list of labels.\n",
    "    :param criterion: Metric to measure the quality of a split. 'gini' for\n",
    "                      Gini Impurity and 'entropy' for Information Gain.\n",
    "    :return: float: Weighted impurity.\n",
    "    \"\"\"\n",
    "    # Calculate the total number of samples in all groups\n",
    "    total = sum(len(group) for group in groups)\n",
    "    # Initialize the weighted sum of impurities\n",
    "    weighted_sum = 0.0\n",
    "\n",
    "    # Iterate through each group\n",
    "    for group in groups:\n",
    "        # Calculate the weight of the group (proportion of total samples)\n",
    "        weight = len(group) / float(total)\n",
    "        # Calculate the impurity of the group using the selected criterion function\n",
    "        impurity = criterion_function[criterion](group)\n",
    "        # Add the weighted impurity to the running sum\n",
    "        weighted_sum += weight * impurity\n",
    "\n",
    "    # Return the final weighted impurity value\n",
    "    return weighted_sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To understand this, we'll calculate the entropy for a toy example and we'll\n",
    "look for the best possible split:\n",
    "![Image Description](04_splits.png)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of #1 split: 0.9510\n",
      "Entropy of #2 split: 0.5510\n"
     ]
    }
   ],
   "source": [
    "# Testing with the toy example:\n",
    "children_1 = [[1, 0, 1], [0, 1]] # Split by gender\n",
    "children_2 = [[1, 1], [0, 0, 1]] # Split by interest in tech\n",
    "\n",
    "print(f\"Entropy of #1 split: {weighted_impurity(children_1, 'entropy'):.4f}\")\n",
    "print(f\"Entropy of #2 split: {weighted_impurity(children_2, 'entropy'):.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This means that the best split is the second one (based on interest in tech."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing the CART algorithm by scratch\n",
    "* We'll build a tree based on the best split (the one that either minimizes\n",
    "the Gini Impurity Index or the one that minimizes Entropy)\n",
    "* The plan is to find the best split for the following toy dataset\n",
    "![Image Description](04_toy_dataset_uinterset_uoccupation.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# We need to rewrite our previous functions in order to handle numpy arrays\n",
    "# as inputs:\n",
    "# Programming a function to calculate the gini impurity index\n",
    "import numpy as np\n",
    "\n",
    "def gini_impurity_np(labels):\n",
    "    \"\"\"\n",
    "    Calculate the Gini impurity of a list of labels.\n",
    "\n",
    "    :param labels: List of labels in a dataset.\n",
    "    :return: Gini impurity index.\n",
    "    \"\"\"\n",
    "    # When the set is empty, it is also pure\n",
    "    if labels.size == 0:\n",
    "        return 0\n",
    "    # Count the occurrences of each label\n",
    "    counts = np.unique(labels, return_counts=True)[1]\n",
    "    # Calculate the fractions of each label's occurrences\n",
    "    fractions = counts / float(len(labels))\n",
    "    # Compute the Gini impurity index\n",
    "    return 1 - np.sum(fractions ** 2)\n",
    "\n",
    "# Calculating the entropy of a given set\n",
    "def entropy_np(labels):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a list of labels.\n",
    "\n",
    "    :param labels: List of labels in a dataset.\n",
    "    :return: Entropy of the dataset.\n",
    "    \"\"\"\n",
    "    # When the set is empty, it has no entropy\n",
    "    if labels.size == 0:\n",
    "        return 0\n",
    "    # Count the occurrences of each label\n",
    "    counts = np.unique(labels, return_counts=True)[1]\n",
    "    # Calculate the fractions of each label's occurrences\n",
    "    fractions = counts / float(len(labels))\n",
    "    # Compute the entropy using the fractions and log base 2\n",
    "    return - np.sum(fractions * np.log2(fractions))\n",
    "\n",
    "# Define a dictionary to map criterion names to their respective functions\n",
    "criterion_function_np = {'gini': gini_impurity, 'entropy': entropy}\n",
    "\n",
    "def weighted_impurity(groups, criterion='gini'):\n",
    "    \"\"\"\n",
    "    Calculate the weighted impurity of children after a split.\n",
    "\n",
    "    :param groups: List of children, and a child consists of a list of labels.\n",
    "    :param criterion: Metric to measure the quality of a split. 'gini' for\n",
    "                      Gini Impurity and 'entropy' for Information Gain.\n",
    "    :return: float: Weighted impurity.\n",
    "    \"\"\"\n",
    "    # Calculate the total number of samples in all groups\n",
    "    total = sum(len(group) for group in groups)\n",
    "    # Initialize the weighted sum of impurities\n",
    "    weighted_sum = 0.0\n",
    "\n",
    "    # Iterate through each group\n",
    "    for group in groups:\n",
    "        weighted_sum += len(group) / float(total) * \\\n",
    "                        criterion_function_np[criterion](group)\n",
    "\n",
    "    # Return the final weighted impurity value\n",
    "    return weighted_sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "# The function should take three arguments: the left group's labels, the right group's labels, and the criterion (either 'gini' or 'entropy'). Here's the correct definition for the weighted_impurity function:\n",
    "\n",
    "def weighted_impurity(left_labels, right_labels, criterion):\n",
    "    total_samples = len(left_labels) + len(right_labels)\n",
    "    if criterion == 'gini':\n",
    "        return (len(left_labels) / total_samples) * gini_impurity_np(left_labels) + \\\n",
    "               (len(right_labels) / total_samples) * gini_impurity_np(right_labels)\n",
    "    elif criterion == 'entropy':\n",
    "        return (len(left_labels) / total_samples) * entropy_np(left_labels) + \\\n",
    "               (len(right_labels) / total_samples) * entropy_np(right_labels)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid criterion value. Choose either 'gini' or 'entropy'.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# Defining a utility function to split a node into left and right children,\n",
    "# based on a feature and a value (target)\n",
    "def split_node(X, y, index, value):\n",
    "    \"\"\"\n",
    "    Splits the dataset X, y based on a feature and a value\n",
    "    @param X: numpy.ndarray, a feature of the dataset\n",
    "    @param y: numpy.ndarray, a target of the dataset\n",
    "    @param index: int, index of the feature used for splitting [column]\n",
    "    @param value: value of the feature used for splitting [unique value]\n",
    "    @return: list, list, left and right child, a child is in the format of\n",
    "    [X, y]\n",
    "    \"\"\"\n",
    "    # All of the rows from the feature column\n",
    "    x_index = X[:, index]\n",
    "    # If the feature is numerical\n",
    "    if X[0, index].dtype.kind in ['i', 'f']:\n",
    "        mask = x_index >= value\n",
    "    # If the feature is categorical\n",
    "    else:\n",
    "        mask = x_index == value\n",
    "    # The left child contains rows of X and y for which the mask array has False values (using the bitwise NOT operator ~ to invert the mask).\n",
    "    left = [X[~mask, :], y[~mask]]\n",
    "    #  The right child contains rows of X and y for which the mask array has True values.\n",
    "    right = [X[mask, :], y[mask]]\n",
    "    return left, right\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# We now implement the greedy search function, which tries out all possible\n",
    "# splits and returns the best one given a selection criterion, along with the\n",
    "# resulting children:\n",
    "def get_best_split(X, y, criterion):\n",
    "    # Initialize variables to keep track of the best split found so far\n",
    "    best_index, best_value, best_score, children = None, None, 1, None\n",
    "\n",
    "    # Iterate through all features (columns) in the dataset X\n",
    "    for index in range(len(X[0])):\n",
    "        # Iterate through all unique values in the current feature column\n",
    "        for value in np.sort(np.unique(X[:, index])):\n",
    "            # Split the dataset based on the current feature and value\n",
    "            groups = split_node(X, y, index, value)\n",
    "            # Calculate the weighted impurity of the resulting children groups\n",
    "            impurity = weighted_impurity(groups[0][1], groups[1][1], criterion)\n",
    "            # Check if the current split is better than the best split found so far\n",
    "            if impurity < best_score:\n",
    "                # Update the best split information (index, value, score, and children)\n",
    "                best_index, best_value, best_score, children = index, value, \\\n",
    "                                                               impurity, groups\n",
    "\n",
    "    # Return the best split information as a dictionary\n",
    "    return {'index': best_index, 'value': best_value, 'children': children}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# The most frequent class (label) among the training data points that have\n",
    "# reached that leaf node. In other words, it is the most common class among the samples that belong to the leaf node.\n",
    "def get_leaf(labels):\n",
    "    # Obtain the leaf as the majority of the labels\n",
    "    return np.bincount(labels).argmax()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The following recursive function links everything together.\n",
    "* It assigns a leaf node if one of two child nodes is empty\n",
    "* It assigns a leaf node if the current branch depth exceeds the maximum\n",
    "depth allowed.\n",
    "* It assigns a leaf node if the node does not contain sufficient samples\n",
    "required for a further split.\n",
    "* Otherwise, it proceeds with a further split with the optimal splitting point.\n",
    "* This function is responsible for recursively constructing the decision tree by splitting the nodes based on the best feature and value, while also taking into consideration the stopping criteria (max_depth and min_size). The tree is grown until the stopping criteria are met or the nodes become pure, meaning they contain samples of only one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_size, depth, criterion):\n",
    "    \"\"\"\n",
    "    Split children of a node to construct new nodes or assign them terminals.\n",
    "    @param node: dict, with children info\n",
    "    @param max_depth: int, maximal depth of the tree\n",
    "    @param min_size: int, minimal samples required to further split a child\n",
    "    @param depth: int, current depth of the node\n",
    "    @param criterion: gini or entropy\n",
    "    @return: null\n",
    "    \"\"\"\n",
    "    # Unpack the children (left and right) from the input node dictionary\n",
    "    left, right = node['children']\n",
    "\n",
    "    # If there are no samples in the left child, assign the majority label of the right child to the node and return\n",
    "    if left[1].size == 0:\n",
    "        node['right'] = get_leaf(right[1])\n",
    "        return\n",
    "    # If there are no samples in the right child, assign the majority label of the left child to the node and return\n",
    "    if right[1].size == 0:\n",
    "        node['left'] = get_leaf(left[1])\n",
    "        return\n",
    "\n",
    "    # Check if the current depth exceeds the maximal depth allowed for the tree\n",
    "    if depth >= max_depth:\n",
    "        # If it exceeds the maximal depth, assign majority labels to both children and return\n",
    "        node['left'], node['right'] = get_leaf(left[1]), get_leaf(right[1])\n",
    "        return\n",
    "\n",
    "    # Check if the left child has enough samples to be further split\n",
    "    if left[1].size <= min_size:\n",
    "        # If not, assign the majority label to the left child\n",
    "        node['left'] = get_leaf(left[1])\n",
    "    else:\n",
    "        # If it has enough samples, further split the left child\n",
    "        result = get_best_split(left[0], left[1], criterion)\n",
    "        result_left, result_right = result['children']\n",
    "        # Check if there are no samples in the left or right child of the split\n",
    "        if result_left[1].size == 0:\n",
    "            node['left'] = get_leaf(result_right[1])\n",
    "        elif result_right[1].size == 0:\n",
    "            node['left'] = get_leaf(result_left[1])\n",
    "        else:\n",
    "            # If both children have samples, store the split information in the node and continue splitting\n",
    "            node['left'] = result\n",
    "            split(node['left'], max_depth, min_size, depth + 1, criterion)\n",
    "\n",
    "    # Check if the right child has enough samples to be further split\n",
    "    if right[1].size <= min_size:\n",
    "        # If not, assign the majority label to the right child\n",
    "        node['right'] = get_leaf(right[1])\n",
    "    else:\n",
    "        # If it has enough samples, further split the right child\n",
    "        result = get_best_split(right[0], right[1], criterion)\n",
    "        result_left, result_right = result['children']\n",
    "        # Check if there are no samples in the left or right child of the split\n",
    "        if result_left[1].size == 0:\n",
    "            node['right'] = get_leaf(result_right[1])\n",
    "        elif result_right[1].size == 0:\n",
    "            node['right'] = get_leaf(result_left[1])\n",
    "        else:\n",
    "            # If both children have samples, store the split information in the node and continue splitting\n",
    "            node['right'] = result\n",
    "            split(node['right'], max_depth, min_size, depth + 1, criterion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The entry point of the tree's construction is as follows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "def train_tree(X_train, y_train, max_depth, min_size, criterion = 'gini'):\n",
    "    X = np.array(X_train)\n",
    "    y = np.array(y_train)\n",
    "    root = get_best_split(X, y, criterion)\n",
    "    split(root, max_depth, min_size, 1, criterion)\n",
    "    return root\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "{'index': 0,\n 'value': 'fashion',\n 'children': ([array([['tech', 'professional'],\n          ['sports', 'student'],\n          ['tech', 'student'],\n          ['tech', 'retired'],\n          ['sports', 'professional']], dtype='<U12'),\n   array([1, 0, 1, 0, 1])],\n  [array([['fashion', 'student'],\n          ['fashion', 'professional']], dtype='<U12'),\n   array([0, 0])]),\n 'left': {'index': 1,\n  'value': 'professional',\n  'children': ([array([['sports', 'student'],\n           ['tech', 'student'],\n           ['tech', 'retired']], dtype='<U12'),\n    array([0, 1, 0])],\n   [array([['tech', 'professional'],\n           ['sports', 'professional']], dtype='<U12'),\n    array([1, 1])]),\n  'left': 0,\n  'right': 1},\n 'right': 0}"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating the toy dataset\n",
    "X_train = [['tech', 'professional'],\n",
    "           ['fashion', 'student'],\n",
    "           ['fashion', 'professional'],\n",
    "           ['sports', 'student'],\n",
    "           ['tech', 'student'],\n",
    "           ['tech', 'retired'],\n",
    "           ['sports', 'professional']]\n",
    "y_train = [1, 0, 0, 0, 1, 0, 1]\n",
    "tree = train_tree(X_train, y_train, 2, 2)\n",
    "tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- X1 is not fashion\n",
      "  |- X2 is not professional\n",
      "    [0]\n",
      "  |- X2 is professional\n",
      "    [1]\n",
      "|- X1 is fashion\n",
      "  [0]\n"
     ]
    }
   ],
   "source": [
    "# Auxiliar function to visualize the tree that we built using the CART\n",
    "# algorithm.\n",
    "CONDITION = {'numerical': {'yes': '>=', 'no': '<'},\n",
    "              'categorical': {'yes': 'is', 'no': 'is not'}}\n",
    "def visualize_tree(node, depth=0):\n",
    "     if isinstance(node, dict):\n",
    "         if node['value'].dtype.kind in ['i', 'f']:\n",
    "             condition = CONDITION['numerical']\n",
    "         else:\n",
    "             condition = CONDITION['categorical']\n",
    "         print('{}|- X{} {} {}'.format(depth * '  ',\n",
    "             node['index'] + 1, condition['no'], node['value']))\n",
    "         if 'left' in node:\n",
    "             visualize_tree(node['left'], depth + 1)\n",
    "         print('{}|- X{} {} {}'.format(depth * '  ',\n",
    "             node['index'] + 1, condition['yes'], node['value']))\n",
    "         if 'right' in node:\n",
    "             visualize_tree(node['right'], depth + 1)\n",
    "     else:\n",
    "         print(f\"{depth * '  '}[{node}]\")\n",
    "visualize_tree(tree)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The previous result is a representation of the best split possible. It's\n",
    "based on the one we built by hand using the gini impurity index.\n",
    "![Image Description](04_toy_dataset_gini_split.png)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- X2 < 4\n",
      "  |- X1 < 7\n",
      "    [1]\n",
      "  |- X1 >= 7\n",
      "    [0]\n",
      "|- X2 >= 4\n",
      "  |- X1 < 2\n",
      "    [1]\n",
      "  |- X1 >= 2\n",
      "    [0]\n"
     ]
    }
   ],
   "source": [
    "# Testing a numerical example\n",
    "X_train_n = [[6, 7],\n",
    "             [2, 4],\n",
    "             [7, 2],\n",
    "             [3, 6],\n",
    "             [4, 7],\n",
    "             [5, 2],\n",
    "             [1, 6],\n",
    "             [2, 0],\n",
    "             [6, 3],\n",
    "             [4, 1]]\n",
    "y_train_n = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "tree = train_tree(X_train_n, y_train_n, 2, 2)\n",
    "visualize_tree(tree)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
